{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "planned-improvement",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The `LibsvmDataset` class is designed to facilitate users downloading datasets from [LIBSVM Data repository](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) and performing some basic data cleaning tasks.\n",
    "\n",
    "Current implementation allows user to download datasets for both `binary` classification task and `regression` task.\n",
    "\n",
    "The API documentation can be found [here](https://roth.rbind.io/resources/software/libsvmdata-downloader/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-arrest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T01:31:36.297213Z",
     "iopub.status.busy": "2021-08-04T01:31:36.296425Z",
     "iopub.status.idle": "2021-08-04T01:31:36.303420Z",
     "shell.execute_reply": "2021-08-04T01:31:36.301655Z",
     "shell.execute_reply.started": "2021-08-04T01:31:36.297044Z"
    }
   },
   "source": [
    "# Downloading\n",
    "\n",
    "`LibsvmDataset` provides a `getAndClean` method (we will explain later on what types of data clean can be performed) to download a particular dataset. Under the hook, this method utilizes an url linking to the dataset to download.\n",
    "This url can either be provided by users through the `download_url` argument or generated internaly by a combination of `task` argument and `dataset` argument.\n",
    "\n",
    "The following code snipts will demonstrate these two methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-opposition",
   "metadata": {},
   "source": [
    "## Option 1: Through the `download_url` argument \n",
    "\n",
    "For exmaple, assume we want to download the `a1a` dataset for the `binary` classification task. Then we can go to https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#a1a and find the download link to the dataset `a1a` under the \"File\" tag.\n",
    "Then right click it and hit \"copy link\" button. The download link is https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a1a.\n",
    "Provide this link to the `LibsvmDataset`'s `getAndClean`  method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indian-power",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T01:49:03.332053Z",
     "iopub.status.busy": "2021-08-04T01:49:03.331537Z",
     "iopub.status.idle": "2021-08-04T01:49:06.539817Z",
     "shell.execute_reply": "2021-08-04T01:49:06.538650Z",
     "shell.execute_reply.started": "2021-08-04T01:49:03.331960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You choose to use the url option.\n",
      "Parsed task: [binary] | Parsed dataset: [a1a]\n",
      "Parsed download_url:[https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a1a]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (114818 of 114818) |################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mdataset [a1a] is downloaded at [./raw/binary].\u001b[0m\n",
      "Original y-label range: { -1.0, 1.0 } -> New y-label range: { -1.0, 1.0 }\n",
      "Perform normalization:feat-11\n",
      "\u001b[92mSuccess: File saved at [./clean/binary]!\u001b[0m\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    }
   ],
   "source": [
    "from LibsvmDataset import *\n",
    "# create a instance\n",
    "# download_dir: A string specifies the place to store the downloaded raw dataset.\n",
    "# cleand_dir: A string specifies the place to store the cleaned dataset.\n",
    "libclass = LibsvmDataset(download_dir=\"./raw\", \n",
    "                         cleand_dir=\"./clean\")\n",
    "libclass.getAndClean(download_url='https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a1a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-seattle",
   "metadata": {},
   "source": [
    "## Option 2: Through the combination of `task` and `dataset` arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "personalized-exchange",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T02:02:07.209979Z",
     "iopub.status.busy": "2021-08-04T02:02:07.209691Z",
     "iopub.status.idle": "2021-08-04T02:02:09.594290Z",
     "shell.execute_reply": "2021-08-04T02:02:09.593462Z",
     "shell.execute_reply.started": "2021-08-04T02:02:07.209949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You choose to use the task+dataset option.\n",
      "Parsed task: [binary] | Parsed dataset: [a2a]\n",
      "Parsed download_url:[https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a2a]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (162053 of 162053) |################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mdataset [a2a] is downloaded at [./raw/binary].\u001b[0m\n",
      "Original y-label range: { -1.0, 1.0 } -> New y-label range: { -1.0, 1.0 }\n",
      "Perform normalization:feat-11\n",
      "\u001b[92mSuccess: File saved at [./clean/binary]!\u001b[0m\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    }
   ],
   "source": [
    "# assume we want to download a2a dataset\n",
    "libclass.getAndClean(task='binary', dataset='a2a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-freedom",
   "metadata": {},
   "source": [
    "**Note:** To use this Option 2, the users should provide correct values to `task` and `dataset` arguments. The current implementation includes all small and moderate size datasets for both `binary` and `regression` tasks. To see all available(built-in) combinations of values for the `task` and `dataset` arguments. One can use the `getAvailable()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wooden-intersection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T02:03:57.051040Z",
     "iopub.status.busy": "2021-08-04T02:03:57.050715Z",
     "iopub.status.idle": "2021-08-04T02:03:57.070775Z",
     "shell.execute_reply": "2021-08-04T02:03:57.069998Z",
     "shell.execute_reply.started": "2021-08-04T02:03:57.051000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current supported tasks are:\n",
      " ['binary'] ['regression']\n",
      "=====================================\n",
      "For task:['binary'], available datasets are:\n",
      "----------------------------------------------------\n",
      " 'a1a', 'a2a', 'a3a', 'a4a', 'a5a',\n",
      "\n",
      " 'a6a', 'a7a', 'a8a', 'a9a', 'a1a.t',\n",
      "\n",
      " 'a2a.t', 'a3a.t', 'a4a.t', 'a5a.t', 'a6a.t',\n",
      "\n",
      " 'a7a.t', 'a8a.t', 'a9a.t', 'australian', 'breast-cancer',\n",
      "\n",
      " 'cod-rna', 'cod-rna.t', 'cod-rna.r', 'colon-cancer.bz2', 'covtype.libsvm.binary.bz2',\n",
      "\n",
      " 'diabetes', 'duke.bz2', 'fourclass', 'german.numer', 'gisette_scale.bz2',\n",
      "\n",
      " 'gisette_scale.t.bz2', 'heart', 'ijcnn1.bz2', 'ionosphere_scale', 'leu.bz2',\n",
      "\n",
      " 'leu.bz2.t', 'liver-disorders', 'liver-disorders.t', 'mushrooms', 'phishing',\n",
      "\n",
      " 'skin_nonskin', 'splice', 'splice.t', 'sonar_scale', 'svmguide1',\n",
      "\n",
      " 'svmguide1.t', 'svmguide3', 'svmguide3.t', 'w1a', 'w2a',\n",
      "\n",
      " 'w3a', 'w4a', 'w5a', 'w6a', 'w7a',\n",
      "\n",
      " 'w8a', 'w1a.t', 'w2a.t', 'w3a.t', 'w4a.t',\n",
      "\n",
      " 'w5a.t', 'w6a.t', 'w7a.t', 'w8a.t',\n",
      "\n",
      "For task:['regression'], available datasets are:\n",
      "----------------------------------------------------\n",
      " 'abalone', 'bodyfat', 'cadata', 'cpusmall', 'log1p.E2006.train.bz2',\n",
      "\n",
      " 'log1p.E2006.test.bz2 E2006.train.bz2', 'E2006.test.bz2', 'eunite2001', 'eunite2001.t', 'eunite2001.m',\n",
      "\n",
      " 'housing', 'mg', 'mpg', 'pyrim', 'space_ga',\n",
      "\n",
      " 'triazines', 'YearPredictionMSD.bz2', 'YearPredictionMSD.t.bz2',\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "libclass.getAvailable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-puppy",
   "metadata": {},
   "source": [
    "If we want to download the dataset `avazu-app.bz2`, which is not available in the above list. What will happens? A error message will be thrown out. (In this case, we recommend users to consider the Option 1, i.e., providing an download url.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "possible-respondent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T02:15:52.817459Z",
     "iopub.status.busy": "2021-08-04T02:15:52.817148Z",
     "iopub.status.idle": "2021-08-04T02:15:52.822856Z",
     "shell.execute_reply": "2021-08-04T02:15:52.821644Z",
     "shell.execute_reply.started": "2021-08-04T02:15:52.817418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You choose to use the task+dataset option.\n",
      "\u001b[91mError occurs!\n",
      "  1.Either the input dataset:[avazu-app.bz2] is not intended for the task:[binary].\n",
      "  2.Or the input dataset:[avazu-app.bz2] is not in the built-in database.\n",
      "If you are sure the latter case happens, you can provide an url pointing to the desired dataset.\u001b[0m\n",
      "\u001b[93mFail to generate download url, please check your inputs.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# An error happens. It matches the second cause.\n",
    "libclass.getAndClean(task='binary', dataset='avazu-app.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-drilling",
   "metadata": {},
   "source": [
    "Also, if a user gives a `dataset` name in the above list,  but mis-specify the `task`, the same error message will be thrown out, which matches the first case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "answering-mandate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T02:18:58.776893Z",
     "iopub.status.busy": "2021-08-04T02:18:58.776565Z",
     "iopub.status.idle": "2021-08-04T02:18:58.782269Z",
     "shell.execute_reply": "2021-08-04T02:18:58.781116Z",
     "shell.execute_reply.started": "2021-08-04T02:18:58.776858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You choose to use the task+dataset option.\n",
      "\u001b[91mError occurs!\n",
      "  1.Either the input dataset:[a1a] is not intended for the task:[regression].\n",
      "  2.Or the input dataset:[a1a] is not in the built-in database.\n",
      "If you are sure the latter case happens, you can provide an url pointing to the desired dataset.\u001b[0m\n",
      "\u001b[93mFail to generate download url, please check your inputs.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# An error happens. It matches the second cause.\n",
    "libclass.getAndClean(task='regression', dataset='a1a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-wrong",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "Currently supported cleaning tasks include:\n",
    "\n",
    "1. Change the label for binary classification. If users want to perform binary classification, the labels can set to {-1,1} by setting `binary_label` argument to '{-1,1}'; or set to {0,1} by providing '{0,1}'.\n",
    "\n",
    "2. Feature-wise normalization. Users can normalize each feature to either range [-1,1] or [0,1] by setting the `normalization` argument to `feat-11` or `feat01`  respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-restoration",
   "metadata": {},
   "source": [
    "# Advanced Useage\n",
    "\n",
    "Users might want to download a list of datasets all at once. This is achieved by using the method `getAndCleanFromFile` method.\n",
    "In this case, users need to provide a `txt` file, where each row is a dataset name. Two samples `txt` files, `libsvm_binary_small.txt` and `libsvm_regression.txt` are provided in this repo for demonstration. \n",
    "\n",
    "**Note**: Users can put a \"#\" in front of the dataset name, in the case, the `getAndCleanFromFile` method will skip this dataset. Again in this scenario, if the dataset  specified in the txt file is not available, an error will be thrown out (but won't crash the code). **When choose the avaiable datasets, we intentionally exclude the large datasets. The first reason is that it takes long time to download. We hope users to download them one by one through the `getAndClean` method. The second reason is that usually these large datasets have multiple verisons, we want users to figure out which one they want to download and get the correct download url on their own.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "appropriate-trinity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T02:33:21.018886Z",
     "iopub.status.busy": "2021-08-04T02:33:21.018293Z",
     "iopub.status.idle": "2021-08-04T02:33:25.064717Z",
     "shell.execute_reply": "2021-08-04T02:33:25.063674Z",
     "shell.execute_reply.started": "2021-08-04T02:33:21.018821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 2 datasets from ./libsvm_regression.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (258705 of 258705) |################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mdataset [abalone] is downloaded at [./raw/regression].\u001b[0m\n",
      "Perform normalization:feat-11\n",
      "  col:0: max:3.000e+00 | min:1.000e+00\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:3: max:1.130e+00 | min:0.000e+00\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:4: max:2.825e+00 | min:2.000e-03\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:5: max:1.488e+00 | min:1.000e-03\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:7: max:1.005e+00 | min:1.500e-03\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "\u001b[92mSuccess: File saved at [./clean/regression]!\u001b[0m\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (28223 of 28223) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mdataset [bodyfat] is downloaded at [./raw/regression].\u001b[0m\n",
      "Perform normalization:feat-11\n",
      "  col:0: max:4.750e+01 | min:0.000e+00\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:1: max:8.100e+01 | min:2.200e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:2: max:3.631e+02 | min:1.185e+02\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:3: max:7.775e+01 | min:2.950e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:4: max:5.120e+01 | min:3.110e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:5: max:1.362e+02 | min:7.930e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:6: max:1.481e+02 | min:6.940e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:7: max:1.477e+02 | min:8.500e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:8: max:8.730e+01 | min:4.720e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:9: max:4.910e+01 | min:3.300e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:10: max:3.390e+01 | min:1.910e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:11: max:4.500e+01 | min:2.480e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:12: max:3.490e+01 | min:2.100e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "  col:13: max:2.140e+01 | min:1.580e+01\n",
      "  Apply feature-wise [-1,1] scaling...\n",
      "\u001b[92mSuccess: File saved at [./clean/regression]!\u001b[0m\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "Summary:\n",
      "\u001b[92mPlan to download: [2] datasets| Successfully download: [2] datasets | Successfully clean: [2] datasets.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "file_path = './libsvm_regression.txt'\n",
    "libclass.getAndCleanFromFile(file_path,\n",
    "                             task='regression', \n",
    "                             binary_lable='{-1,1}', \n",
    "                             normalization='feat-11')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-driving",
   "metadata": {},
   "source": [
    "# Final Remarks\n",
    "\n",
    "By default, the `LibsvmDataset` class will check the whether the dataset has been downloaded and cleaned. If it is true, no further action is taken.\n",
    "One can set `force_download` and `force_clean` to `True`. Then the dataset will be downloaded and cleaned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
